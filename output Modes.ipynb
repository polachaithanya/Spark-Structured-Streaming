{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f4207ea1-c8cf-43f2-bf51-0c2ebb1c44a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Append(default)--writes the new arrived data      \n",
    "- Completes--writes entore results every time\n",
    "- update---updates the recors id the data matches in table and file, writes only new rows that have changed since last micro batch\n",
    "- option(maxFilesPerTrigger,1)--to be written in read----even though we have multiple files only 1 files is read at a time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c0309274-7d76-4f41-8025-cc3097f09cab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "customer_schema_update = StructType(\n",
    "    fields = [\n",
    "        StructField('customer_id',IntegerType()),\n",
    "        StructField('customer_name',StringType()),\n",
    "        StructField('date_of_birth',DateType()),\n",
    "        StructField('telephone',StringType()),\n",
    "        StructField('email',StringType()),\n",
    "        StructField('member_since',DateType()),\n",
    "        StructField('created_timestamp',TimestampType()),\n",
    "\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c72c3516-2051-413f-93b9-f9cf94427697",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "customer_df_update = (spark.readStream.format('json')\n",
    "              .schema(customer_schema_update)\n",
    "              .load(\"/Volumes/gizmobox/landing/operational_data/customers_stream/\")\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f6ea446d-a204-4e85-a55a-ef0ddd53f74c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, current_timestamp, row_number, split\n",
    "customer_transform_df_update = (\n",
    "    customer_df_update\n",
    "    .withColumn(\"fname\", split(col(\"customer_name\"), \" \").getItem(0))\n",
    "    .withColumn(\"lname\", split(col(\"customer_name\"), \" \").getItem(1))\n",
    "    .withColumn(\"created_time\", current_timestamp())\n",
    "    .filter(col(\"customer_id\").isNotNull())\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6fc1898d-62d0-4083-a057-18188d0a7d70",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# for ouput mode update--delta format will not work\n",
    "#complete only works if the data is aggregrated\n",
    "stream_query_updated = (customer_transform_df_update.writeStream\n",
    "                .format(\"delta\")\n",
    "                .outputMode(\"append\")\n",
    "                .option(\"checkpointLocation\",\"/Volumes/gizmobox/landing/operational_data/customers_stream/checkpoint_stream_update\")\n",
    "                .toTable(\"gizmobox.bronze.customer_stream_update\")\n",
    "                \n",
    "                \n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "output Modes",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
